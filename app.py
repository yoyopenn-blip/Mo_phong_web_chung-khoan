# === C√ÅC TH∆Ø VI·ªÜN C·∫¶N THI·∫æT ===
import streamlit as st
import pandas as pd
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from datetime import datetime, timedelta
import time
import warnings
import numpy as np
import requests
from io import BytesIO
import zipfile

# T·∫Øt warnings
warnings.filterwarnings('ignore')

# Try import vnstock3
try:
    from vnstock3 import Vnstock
    VNSTOCK_AVAILABLE = True
except ImportError:
    VNSTOCK_AVAILABLE = False
    st.warning("‚ö†Ô∏è vnstock3 ch∆∞a c√†i ƒë·∫∑t. S·ª≠ d·ª•ng ngu·ªìn d·ªØ li·ªáu CafeF.")

# === C·∫§U H√åNH TRANG WEB ===
st.set_page_config(
    page_title="VN Stock Analytics", 
    page_icon="üìà", 
    layout="wide",
    initial_sidebar_state="expanded"
)

# === CUSTOM CSS ===
st.markdown("""
    <style>
    @import url('https://fonts.googleapis.com/css2?family=Space+Grotesk:wght@400;500;600;700&family=Inter:wght@400;500;600;700&display=swap');
    
    * {
        font-family: 'Space Grotesk', 'Inter', sans-serif;
    }
    
    .main {
        background: linear-gradient(-45deg, #0a0e1f, #1a1532, #2a1f3a, #151b35);
        background-size: 400% 400%;
        animation: gradientShift 15s ease infinite;
        padding: 0;
    }
    
    @keyframes gradientShift {
        0% { background-position: 0% 50%; }
        50% { background-position: 100% 50%; }
        100% { background-position: 0% 50%; }
    }
    
    .main-header {
        background: rgba(92, 88, 187, 0.15);
        backdrop-filter: blur(20px);
        -webkit-backdrop-filter: blur(20px);
        border: 1px solid rgba(185, 87, 206, 0.2);
        padding: 2.5rem;
        border-radius: 25px;
        margin-bottom: 2rem;
        box-shadow: 0 8px 32px rgba(89, 148, 206, 0.2), inset 0 1px 1px rgba(255, 255, 255, 0.1);
        text-align: center;
        position: relative;
        overflow: hidden;
    }
    
    .main-header h1 {
        color: #ffffff !important;
        font-size: 3rem;
        font-weight: 700;
        margin: 0;
        text-shadow: 0 2px 10px rgba(92, 88, 187, 0.8);
    }
    
    .main-header p {
        color: #ffffff !important;
        font-size: 1.2rem;
        margin-top: 0.8rem;
        font-weight: 500;
        text-shadow: 0 1px 5px rgba(0, 0, 0, 0.5);
    }
    
    .stMetric {
        background: rgba(58, 78, 147, 0.2);
        backdrop-filter: blur(10px);
        padding: 1.8rem;
        border-radius: 20px;
        box-shadow: 0 8px 32px rgba(0, 0, 0, 0.3), inset 0 1px 1px rgba(255, 255, 255, 0.05);
        border: 1px solid rgba(92, 88, 187, 0.3);
        transition: all 0.4s cubic-bezier(0.4, 0, 0.2, 1);
    }
    
    .stMetric:hover {
        transform: translateY(-8px) scale(1.02);
        box-shadow: 0 20px 60px rgba(92, 88, 187, 0.4);
        border-color: rgba(185, 87, 206, 0.6);
    }
    
    [data-testid="stSidebar"] {
        background: linear-gradient(180deg, rgba(58, 78, 147, 0.95) 0%, rgba(26, 21, 50, 0.98) 100%);
        backdrop-filter: blur(20px);
    }
    
    .stButton > button {
        background: linear-gradient(135deg, #5c58bb 0%, #b957ce 100%);
        color: white;
        border: none;
        border-radius: 15px;
        padding: 1rem 2.5rem;
        font-weight: 700;
        box-shadow: 0 4px 15px rgba(92, 88, 187, 0.4);
        transition: all 0.3s ease;
        width: 100%;
    }
    
    .stButton > button:hover {
        transform: translateY(-3px);
        box-shadow: 0 8px 25px rgba(92, 88, 187, 0.6);
    }
    
    .data-table-container {
        background: rgba(58, 78, 147, 0.15);
        backdrop-filter: blur(20px);
        border: 1px solid rgba(92, 88, 187, 0.3);
        border-radius: 25px;
        padding: 2rem;
        margin: 2rem 0;
        box-shadow: 0 8px 32px rgba(0, 0, 0, 0.4);
    }
    
    .chart-container {
        background: rgba(58, 78, 147, 0.15);
        backdrop-filter: blur(20px);
        padding: 2.5rem;
        border-radius: 25px;
        box-shadow: 0 10px 40px rgba(0, 0, 0, 0.4);
        border: 1px solid rgba(92, 88, 187, 0.3);
        margin: 2rem 0;
    }
    
    .stats-card {
        background: rgba(58, 78, 147, 0.2);
        backdrop-filter: blur(10px);
        border: 1px solid rgba(92, 88, 187, 0.3);
        border-radius: 15px;
        padding: 1.5rem;
        margin: 1rem 0;
        transition: all 0.3s ease;
    }
    
    .stats-card:hover {
        border-color: rgba(185, 87, 206, 0.5);
        transform: translateY(-3px);
    }
    </style>
    """, unsafe_allow_html=True)

# === HEADER ===
st.markdown("""
    <div class="main-header">
        <h1>‚ö° VN STOCK ANALYTICS PRO</h1>
        <p>üöÄ N·ªÅn t·∫£ng ph√¢n t√≠ch ch·ª©ng kho√°n th√¥ng minh v·ªõi vnstock3 API & CafeF</p>
    </div>
    """, unsafe_allow_html=True)

# === PH·∫¶N 1: H√ÄM T·∫¢I D·ªÆ LI·ªÜU ===

def process_cafef_zip(zip_content, date_info):
    """X·ª≠ l√Ω file ZIP t·ª´ CafeF v·ªõi validation t·ªët h∆°n"""
    try:
        with zipfile.ZipFile(zip_content) as z:
            # Li·ªát k√™ t·∫•t c·∫£ files
            all_files = z.namelist()
            st.info(f"üì¶ T·ªïng s·ªë files trong ZIP: {len(all_files)}")
            
            csv_files = [f for f in all_files if f.lower().endswith('.csv')]
            
            if not csv_files:
                st.error(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y file CSV trong archive")
                st.info(f"üìÅ Files t√¨m th·∫•y: {', '.join(all_files[:10])}...")
                return None
            
            st.info(f"üìÇ T√¨m th·∫•y {len(csv_files)} file CSV, ƒëang x·ª≠ l√Ω...")
            
            all_data = []
            processed_files = 0
            error_files = 0
            
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            for idx, csv_file in enumerate(csv_files):
                try:
                    status_text.text(f"‚è≥ ƒêang x·ª≠ l√Ω file {idx+1}/{len(csv_files)}: {csv_file[:50]}...")
                    progress_bar.progress((idx + 1) / len(csv_files))
                    
                    with z.open(csv_file) as f:
                        # Th·ª≠ nhi·ªÅu encoding
                        encodings = ['utf-8', 'utf-8-sig', 'latin1', 'cp1252', 'iso-8859-1']
                        df = None
                        
                        for encoding in encodings:
                            try:
                                f.seek(0)
                                df = pd.read_csv(f, encoding=encoding, on_bad_lines='skip')
                                break
                            except (UnicodeDecodeError, pd.errors.ParserError):
                                continue
                        
                        if df is None or df.empty:
                            error_files += 1
                            continue
                        
                        # Debug: Hi·ªÉn th·ªã columns c·ªßa file ƒë·∫ßu ti√™n
                        if idx == 0:
                            st.info(f"üîç C·ªôt trong file m·∫´u: {', '.join(df.columns.tolist()[:10])}")
                        
                        # Mapping c·ªôt - m·ªü r·ªông h∆°n
                        column_mapping = {
                            # Ti·∫øng Vi·ªát
                            'M√£ CK': '<Ticker>', 'M√£': '<Ticker>', 'TICKER': '<Ticker>', 'Ma': '<Ticker>',
                            'Ng√†y': '<DTYYYYMMDD>', 'Th·ªùi gian': '<DTYYYYMMDD>', 'NGAY': '<DTYYYYMMDD>',
                            'ThoiGian': '<DTYYYYMMDD>', 'Thoi gian': '<DTYYYYMMDD>',
                            'M·ªü c·ª≠a': '<Open>', 'Gi√° m·ªü c·ª≠a': '<Open>', 'OPEN': '<Open>', 'GiaMoCua': '<Open>',
                            'Cao nh·∫•t': '<High>', 'Gi√° cao nh·∫•t': '<High>', 'HIGH': '<High>', 'GiaCaoNhat': '<High>',
                            'Th·∫•p nh·∫•t': '<Low>', 'Gi√° th·∫•p nh·∫•t': '<Low>', 'LOW': '<Low>', 'GiaThapNhat': '<Low>',
                            'ƒê√≥ng c·ª≠a': '<Close>', 'Gi√° ƒë√≥ng c·ª≠a': '<Close>', 'CLOSE': '<Close>', 'GiaDongCua': '<Close>',
                            'ƒê.C·ª≠a': '<Close>', 'DC': '<Close>',
                            'KLGD': '<Volume>', 'Kh·ªëi l∆∞·ª£ng': '<Volume>', 'KL': '<Volume>', 'VOLUME': '<Volume>',
                            'KhoiLuong': '<Volume>', 'Khoi luong': '<Volume>',
                            # Ti·∫øng Anh
                            'Code': '<Ticker>', 'Symbol': '<Ticker>', 'Ticker': '<Ticker>',
                            'TradingDate': '<DTYYYYMMDD>', 'Date': '<DTYYYYMMDD>', 
                            'Time': '<DTYYYYMMDD>', 'DateTime': '<DTYYYYMMDD>',
                            'Open': '<Open>', 'OpenPrice': '<Open>',
                            'High': '<High>', 'HighPrice': '<High>',
                            'Low': '<Low>', 'LowPrice': '<Low>',
                            'Close': '<Close>', 'ClosePrice': '<Close>',
                            'Volume': '<Volume>', 'TotalVolume': '<Volume>', 'Vol': '<Volume>'
                        }
                        
                        # ƒê·ªïi t√™n c·ªôt
                        df = df.rename(columns=column_mapping)
                        
                        # Ki·ªÉm tra c√≥ ƒë·ªß c·ªôt c·∫ßn thi·∫øt kh√¥ng
                        if '<Ticker>' not in df.columns or '<Close>' not in df.columns:
                            error_files += 1
                            continue
                        
                        # X·ª≠ l√Ω c·ªôt ng√†y
                        if '<DTYYYYMMDD>' in df.columns:
                            df['<DTYYYYMMDD>'] = pd.to_datetime(df['<DTYYYYMMDD>'], errors='coerce')
                        else:
                            error_files += 1
                            continue
                        
                        # L·ªçc c√°c c·ªôt c·∫ßn thi·∫øt
                        required_cols = ['<Ticker>', '<DTYYYYMMDD>', '<Open>', '<High>', '<Low>', '<Close>', '<Volume>']
                        
                        # Th√™m c√°c c·ªôt thi·∫øu v·ªõi gi√° tr·ªã m·∫∑c ƒë·ªãnh
                        for col in required_cols:
                            if col not in df.columns:
                                if col == '<Open>':
                                    df[col] = df['<Close>']
                                elif col in ['<High>', '<Low>']:
                                    df[col] = df['<Close>']
                                elif col == '<Volume>':
                                    df[col] = 0
                        
                        df = df[required_cols]
                        
                        # Ki·ªÉm tra c√≥ d·ªØ li·ªáu h·ª£p l·ªá kh√¥ng
                        if len(df) > 0:
                            all_data.append(df)
                            processed_files += 1
                        else:
                            error_files += 1
                        
                except Exception as e:
                    error_files += 1
                    if idx < 5:  # Ch·ªâ hi·ªÉn th·ªã l·ªói 5 file ƒë·∫ßu
                        st.warning(f"‚ö†Ô∏è L·ªói file {csv_file}: {str(e)[:100]}")
                    continue
            
            progress_bar.empty()
            status_text.empty()
            
            st.info(f"üìä X·ª≠ l√Ω: {processed_files} th√†nh c√¥ng, {error_files} l·ªói")
            
            if all_data:
                st.info("üîÑ ƒêang g·ªôp v√† l√†m s·∫°ch d·ªØ li·ªáu...")
                combined_df = pd.concat(all_data, ignore_index=True)
                
                st.info(f"üì¶ T·ªïng b·∫£n ghi ban ƒë·∫ßu: {len(combined_df):,}")
                
                # L√†m s·∫°ch d·ªØ li·ªáu
                combined_df = combined_df.dropna(subset=['<DTYYYYMMDD>', '<Close>', '<Ticker>'])
                st.info(f"‚úì Sau khi lo·∫°i NaN: {len(combined_df):,}")
                
                combined_df['<Ticker>'] = combined_df['<Ticker>'].astype(str).str.strip().str.upper()
                combined_df = combined_df[combined_df['<Ticker>'] != '']
                combined_df = combined_df[combined_df['<Ticker>'] != 'NAN']
                st.info(f"‚úì Sau khi lo·∫°i ticker r·ªóng: {len(combined_df):,}")
                
                combined_df = combined_df[combined_df['<Close>'] > 0]
                st.info(f"‚úì Sau khi lo·∫°i gi√° <= 0: {len(combined_df):,}")
                
                combined_df = combined_df.sort_values(['<Ticker>', '<DTYYYYMMDD>'])
                combined_df = combined_df.drop_duplicates(subset=['<Ticker>', '<DTYYYYMMDD>'], keep='last')
                st.info(f"‚úì Sau khi lo·∫°i tr√πng: {len(combined_df):,}")
                
                unique_tickers = len(combined_df['<Ticker>'].unique())
                total_records = len(combined_df)
                
                if total_records > 0:
                    # Debug: Hi·ªÉn th·ªã m·∫´u d·ªØ li·ªáu
                    st.success(f"‚úÖ Th√†nh c√¥ng: {unique_tickers} m√£, {total_records:,} b·∫£n ghi (ng√†y {date_info})")
                    
                    # Hi·ªÉn th·ªã 5 m√£ ƒë·∫ßu ti√™n
                    sample_tickers = sorted(combined_df['<Ticker>'].unique())[:5]
                    st.info(f"üîç M·∫´u m√£: {', '.join(sample_tickers)}")
                    
                    # Hi·ªÉn th·ªã date range
                    min_date = combined_df['<DTYYYYMMDD>'].min()
                    max_date = combined_df['<DTYYYYMMDD>'].max()
                    st.info(f"üìÖ Kho·∫£ng th·ªùi gian: {min_date.strftime('%d/%m/%Y')} - {max_date.strftime('%d/%m/%Y')}")
                    
                    return combined_df
                else:
                    st.error("‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu sau khi l√†m s·∫°ch")
                    return None
            else:
                st.error(f"‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu h·ª£p l·ªá t·ª´ {len(csv_files)} files")
                return None
                
    except zipfile.BadZipFile:
        st.error("‚ùå File t·∫£i v·ªÅ kh√¥ng ph·∫£i ƒë·ªãnh d·∫°ng ZIP h·ª£p l·ªá")
    except Exception as e:
        st.error(f"‚ùå L·ªói x·ª≠ l√Ω ZIP: {str(e)}")
        st.exception(e)
    
    return None

def download_latest_cafef_data():
    """T·ª± ƒë·ªông t√¨m ng√†y c√≥ d·ªØ li·ªáu g·∫ßn nh·∫•t v√† t·∫£i file ZIP t·ª´ CafeF"""
    MAX_DAYS_TO_CHECK = 10
    
    st.info("üîç ƒêang t√¨m d·ªØ li·ªáu CafeF m·ªõi nh·∫•t...")
    
    # V√≤ng l·∫∑p t√¨m ng√†y c√≥ d·ªØ li·ªáu
    for i in range(1, MAX_DAYS_TO_CHECK + 1):
        check_date = datetime.now() - timedelta(days=i)
        date_str_path = check_date.strftime('%Y%m%d')
        date_str_file = check_date.strftime('%d%m%Y')
        
        url = f"https://cafef1.mediacdn.vn/data/ami_data/{date_str_path}/CafeF.SolieuGD.Upto{date_str_file}.zip"
        
        try:
            st.info(f"üîé Ki·ªÉm tra ng√†y: {check_date.strftime('%d-%m-%Y')} (l√πi {i} ng√†y)...")
            
            # Ki·ªÉm tra file c√≥ t·ªìn t·∫°i kh√¥ng
            response = requests.head(url, timeout=10)
            
            st.info(f"üì° HTTP Status: {response.status_code}")
            
            if response.status_code == 200:
                st.success(f"‚úÖ T√¨m th·∫•y d·ªØ li·ªáu ng√†y: {check_date.strftime('%d-%m-%Y')}")
                
                # Hi·ªÉn th·ªã th√¥ng tin file
                if 'content-length' in response.headers:
                    file_size = int(response.headers['content-length']) / (1024 * 1024)
                    st.info(f"üì¶ K√≠ch th∆∞·ªõc file: {file_size:.2f} MB")
                
                # T·∫£i file zip
                st.info("üì• ƒêang t·∫£i d·ªØ li·ªáu...")
                
                download_progress = st.progress(0)
                download_status = st.empty()
                
                with requests.get(url, stream=True, timeout=120) as r:
                    r.raise_for_status()
                    
                    total_size = int(r.headers.get('content-length', 0))
                    downloaded = 0
                    chunks = []
                    
                    for chunk in r.iter_content(chunk_size=8192):
                        if chunk:
                            chunks.append(chunk)
                            downloaded += len(chunk)
                            if total_size > 0:
                                progress = downloaded / total_size
                                download_progress.progress(progress)
                                download_status.text(f"‚è¨ ƒê√£ t·∫£i: {downloaded/(1024*1024):.1f}/{total_size/(1024*1024):.1f} MB")
                    
                    zip_content = BytesIO(b''.join(chunks))
                
                download_progress.empty()
                download_status.empty()
                
                st.success("‚úÖ T·∫£i th√†nh c√¥ng! ƒêang x·ª≠ l√Ω...")
                
                # X·ª≠ l√Ω file zip
                result = process_cafef_zip(zip_content, check_date.strftime('%d-%m-%Y'))
                
                if result is not None:
                    st.balloons()
                    return result
                else:
                    st.error("‚ùå X·ª≠ l√Ω file th·∫•t b·∫°i, th·ª≠ ng√†y kh√°c...")
                    continue
                    
        except requests.exceptions.Timeout:
            st.warning(f"‚è±Ô∏è Timeout khi ki·ªÉm tra ng√†y {check_date.strftime('%d-%m-%Y')}")
            continue
        except requests.exceptions.RequestException as e:
            st.warning(f"üîå L·ªói k·∫øt n·ªëi ng√†y {check_date.strftime('%d-%m-%Y')}: {str(e)[:100]}")
            continue
        except Exception as e:
            st.error(f"‚ùå L·ªói kh√¥ng x√°c ƒë·ªãnh: {str(e)}")
            continue
    
    st.error(f"‚ùå Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu trong v√≤ng {MAX_DAYS_TO_CHECK} ng√†y qua")
    st.info("üí° G·ª£i √Ω: Th·ª≠ s·ª≠ d·ª•ng vnstock3 API ho·∫∑c tƒÉng MAX_DAYS_TO_CHECK")
    return None

def download_stock_data_vnstock(symbol, days_back=365):
    """T·∫£i t·ª´ vnstock3 API"""
    if not VNSTOCK_AVAILABLE:
        return None
        
    try:
        stock = Vnstock().stock(symbol=symbol, source='TCBS')
        end_date = datetime.now().strftime('%Y-%m-%d')
        start_date = (datetime.now() - timedelta(days=days_back)).strftime('%Y-%m-%d')
        
        df = stock.quote.history(start=start_date, end=end_date, interval='1D')
        
        if df is not None and not df.empty:
            df = df.reset_index()
            df = df.rename(columns={
                'time': '<DTYYYYMMDD>', 'open': '<Open>',
                'high': '<High>', 'low': '<Low>',
                'close': '<Close>', 'volume': '<Volume>'
            })
            df['<Ticker>'] = symbol
            
            if not pd.api.types.is_datetime64_any_dtype(df['<DTYYYYMMDD>']):
                df['<DTYYYYMMDD>'] = pd.to_datetime(df['<DTYYYYMMDD>'])
            
            return df[['<Ticker>', '<DTYYYYMMDD>', '<Open>', '<High>', '<Low>', '<Close>', '<Volume>']]
            
    except Exception as e:
        st.error(f"‚ùå L·ªói vnstock3 cho {symbol}: {str(e)}")
    return None

def download_stock_data(symbol, days_back=365, data_source='vnstock3'):
    """T·∫£i d·ªØ li·ªáu t·ª´ ngu·ªìn ƒë∆∞·ª£c ch·ªçn"""
    if data_source == 'vnstock3' and VNSTOCK_AVAILABLE:
        return download_stock_data_vnstock(symbol, days_back)
    elif data_source == 'cafef':
        st.warning("‚ö†Ô∏è CafeF y√™u c·∫ßu t·∫£i to√†n b·ªô th·ªã tr∆∞·ªùng")
        return None
    return None

# === PH·∫¶N 2: CH·ªà B√ÅO K·ª∏ THU·∫¨T ===
def calculate_ma(data, period):
    return data['<Close>'].rolling(window=period).mean()

def calculate_ema(data, period):
    return data['<Close>'].ewm(span=period, adjust=False).mean()

def calculate_bollinger_bands(data, period=20, std_dev=2):
    ma = data['<Close>'].rolling(window=period).mean()
    std = data['<Close>'].rolling(window=period).std()
    return ma, ma + (std * std_dev), ma - (std * std_dev)

def calculate_rsi(data, period=14):
    delta = data['<Close>'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
    rs = gain / loss
    return 100 - (100 / (1 + rs))

# === PH·∫¶N 3: X·ª¨ L√ù OUTLIERS ===
def detect_outliers_iqr(data, column, multiplier=1.5):
    Q1 = data[column].quantile(0.25)
    Q3 = data[column].quantile(0.75)
    IQR = Q3 - Q1
    lower = Q1 - multiplier * IQR
    upper = Q3 + multiplier * IQR
    return data[(data[column] < lower) | (data[column] > upper)], lower, upper

def detect_outliers_zscore(data, column, threshold=3):
    z_scores = np.abs((data[column] - data[column].mean()) / data[column].std())
    return data[z_scores > threshold]

def remove_outliers(data, column, method='iqr', **kwargs):
    if method == 'iqr':
        outliers, lower, upper = detect_outliers_iqr(data, column, **kwargs)
        cleaned = data[(data[column] >= lower) & (data[column] <= upper)]
    else:
        outliers = detect_outliers_zscore(data, column, **kwargs)
        cleaned = data[~data.index.isin(outliers.index)]
    return cleaned, outliers

# === PH·∫¶N 4: CACHE DATA ===
@st.cache_data(ttl=3600)
def get_master_data(symbols_list, data_source='vnstock3'):
    all_data = []
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    for idx, symbol in enumerate(symbols_list):
        status_text.text(f"‚è≥ ƒêang t·∫£i {symbol}...")
        df = download_stock_data(symbol, data_source=data_source)
        if df is not None:
            all_data.append(df)
        progress_bar.progress((idx + 1) / len(symbols_list))
        time.sleep(0.5)
    
    progress_bar.empty()
    status_text.empty()
    
    if all_data:
        combined_df = pd.concat(all_data, ignore_index=True)
        st.success(f"‚úÖ T·∫£i th√†nh c√¥ng {len(all_data)}/{len(symbols_list)} m√£!")
        return combined_df
    return None

@st.cache_data(ttl=3600)
def get_cafef_all_exchanges():
    """T·∫£i d·ªØ li·ªáu t·ª´ CafeF (t·ª± ƒë·ªông t√¨m ng√†y m·ªõi nh·∫•t)"""
    return download_latest_cafef_data()

# === DANH S√ÅCH M√É ===
DEFAULT_STOCKS = ['FPT', 'VNM', 'VIC', 'VHM', 'HPG', 'TCB', 'VCB', 'BID', 'CTG', 'MBB',
                  'VPB', 'MSN', 'MWG', 'PLX', 'GAS', 'VRE', 'VJC', 'SSI', 'HDB', 'STB']

# === SIDEBAR ===
with st.sidebar:
    st.markdown("### ‚öôÔ∏è C·∫§U H√åNH H·ªÜ TH·ªêNG")
    
    # RESET BUTTON
    if st.button("üîÑ RESET D·ªÆ LI·ªÜU", use_container_width=True, type="secondary"):
        keys_to_delete = ['data', 'stock_list', 'data_source']
        for key in keys_to_delete:
            if key in st.session_state:
                del st.session_state[key]
        st.success("‚úÖ ƒê√£ x√≥a d·ªØ li·ªáu!")
        time.sleep(1)
        st.rerun()
    
    st.markdown("---")
    
    # === PH·∫¶N 1: CH·ªåN NGU·ªíN D·ªÆ LI·ªÜU ===
    st.markdown("#### üåê NGU·ªíN D·ªÆ LI·ªÜU")
    
    vnstock_status = "‚úÖ S·∫µn s√†ng" if VNSTOCK_AVAILABLE else "‚ùå Ch∆∞a c√†i"
    vnstock_color = "üü¢" if VNSTOCK_AVAILABLE else "üî¥"
    
    st.markdown(f"""
    <div style="background: rgba(58, 78, 147, 0.2); padding: 1rem; border-radius: 10px; margin-bottom: 1rem;">
        <div style="display: flex; justify-content: space-between; margin-bottom: 0.5rem;">
            <span>üì° vnstock3 API</span>
            <span>{vnstock_color} {vnstock_status}</span>
        </div>
        <div style="display: flex; justify-content: space-between;">
            <span>üì¶ CafeF Auto</span>
            <span>üü¢ S·∫µn s√†ng</span>
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    data_source_options = []
    if VNSTOCK_AVAILABLE:
        data_source_options.append("üì° vnstock3")
    data_source_options.append("üì¶ CafeF")
    
    selected_source = st.radio(
        "Ch·ªçn ngu·ªìn:", 
        data_source_options,
        label_visibility="collapsed",
        key="source_selector"
    )
    
    source = 'vnstock3' if "vnstock3" in selected_source else 'cafef'
    
    # Hi·ªÉn th·ªã tr·∫°ng th√°i ngu·ªìn ƒë√£ ch·ªçn
    if source == 'vnstock3':
        st.success("‚úÖ ƒêang d√πng: **vnstock3 API**")
        st.info("üìä Real-time ‚Ä¢ 1 m√£ ho·∫∑c nhi·ªÅu m√£")
    else:
        st.info("‚úÖ ƒêang d√πng: **CafeF Auto**")
        st.warning("üìä To√†n th·ªã tr∆∞·ªùng ‚Ä¢ T·ª± ƒë·ªông t√¨m ng√†y m·ªõi")
    
    st.markdown("---")

# === PH·∫¶N 2: T·∫¢I D·ªÆ LI·ªÜU (CONDITIONAL UI) ===
with st.sidebar:
    if source == 'vnstock3':
        st.markdown("### üì° VNSTOCK3 - T·∫¢I D·ªÆ LI·ªÜU")
        
        load_mode = st.radio(
            "Ch·ªçn ch·∫ø ƒë·ªô:",
            ["üéØ T·∫£i 1 m√£", "üì¶ T·∫£i nhi·ªÅu m√£"],
            label_visibility="collapsed"
        )
        
        if load_mode == "üéØ T·∫£i 1 m√£":
            st.markdown("#### üîç Nh·∫≠p m√£ c·ªï phi·∫øu")
            single_stock = st.text_input(
                "V√≠ d·ª•: FPT, VNM, VIC...",
                value="FPT",
                key="vnstock_single",
                label_visibility="collapsed"
            ).upper().strip()
            
            if st.button("üöÄ T·∫¢I D·ªÆ LI·ªÜU", use_container_width=True, type="primary"):
                if single_stock:
                    with st.spinner(f"‚è≥ ƒêang t·∫£i {single_stock} t·ª´ vnstock3..."):
                        df = download_stock_data(single_stock, data_source='vnstock3')
                        if df is not None and not df.empty:
                            st.session_state['data'] = df
                            st.session_state['stock_list'] = [single_stock]
                            st.session_state['data_source'] = 'vnstock3'
                            st.success(f"‚úÖ T·∫£i th√†nh c√¥ng {single_stock}!")
                            time.sleep(0.5)
                            st.rerun()
                        else:
                            st.error(f"‚ùå Kh√¥ng t·∫£i ƒë∆∞·ª£c {single_stock}")
                else:
                    st.warning("‚ö†Ô∏è Vui l√≤ng nh·∫≠p m√£ c·ªï phi·∫øu")
        
        else:  # T·∫£i nhi·ªÅu m√£
            st.markdown("#### üì¶ T·∫£i danh s√°ch ph·ªï bi·∫øn")
            st.info(f"S·∫Ω t·∫£i {len(DEFAULT_STOCKS)} m√£ blue-chip")
            
            with st.expander("üìã Xem danh s√°ch"):
                st.write(", ".join(DEFAULT_STOCKS))
            
            if st.button("üì• T·∫¢I DANH S√ÅCH", use_container_width=True, type="primary"):
                with st.spinner(f"‚è≥ ƒêang t·∫£i {len(DEFAULT_STOCKS)} m√£..."):
                    df = get_master_data(DEFAULT_STOCKS, data_source='vnstock3')
                    if df is not None and not df.empty:
                        st.session_state['data'] = df
                        st.session_state['stock_list'] = DEFAULT_STOCKS
                        st.session_state['data_source'] = 'vnstock3'
                        st.success(f"‚úÖ T·∫£i th√†nh c√¥ng {len(DEFAULT_STOCKS)} m√£!")
                        time.sleep(0.5)
                        st.rerun()
                    else:
                        st.error("‚ùå L·ªói t·∫£i d·ªØ li·ªáu")
    
    else:  # CafeF
        st.markdown("### üì¶ CAFEF - T·∫¢I D·ªÆ LI·ªÜU")
        
        # Ki·ªÉm tra xem ƒë√£ c√≥ d·ªØ li·ªáu ch∆∞a
        has_data = 'data' in st.session_state and st.session_state['data'] is not None
        
        if has_data:
            st.success("‚úÖ ƒê√£ c√≥ d·ªØ li·ªáu trong b·ªô nh·ªõ")
            total_stocks = len(st.session_state['data']['<Ticker>'].unique())
            st.info(f"üìä C√≥ {total_stocks} m√£ c·ªï phi·∫øu")
            
            st.markdown("#### üîç T√¨m ki·∫øm m√£ c·ª• th·ªÉ")
            search_stock = st.text_input(
                "Nh·∫≠p m√£ ƒë·ªÉ l·ªçc:",
                key="cafef_search",
                placeholder="V√≠ d·ª•: FPT",
                label_visibility="collapsed"
            ).upper().strip()
            
            if search_stock:
                if st.button("üîç L·ªåC M√É", use_container_width=True):
                    df = st.session_state['data']
                    filtered = df[df['<Ticker>'] == search_stock]
                    if not filtered.empty:
                        st.session_state['data'] = filtered
                        st.session_state['stock_list'] = [search_stock]
                        st.success(f"‚úÖ ƒê√£ l·ªçc {search_stock}")
                        time.sleep(0.5)
                        st.rerun()
                    else:
                        st.error(f"‚ùå Kh√¥ng t√¨m th·∫•y {search_stock}")
            
            if st.button("üîÑ T·∫¢I L·∫†I TO√ÄN B·ªò", use_container_width=True, type="secondary"):
                if 'data' in st.session_state:
                    del st.session_state['data']
                if 'stock_list' in st.session_state:
                    del st.session_state['stock_list']
                st.info("Nh·∫•n n√∫t 'T·∫¢I TO√ÄN TH·ªä TR∆Ø·ªú·ªúNG' ƒë·ªÉ t·∫£i l·∫°i")
                st.rerun()
        
        else:  # Ch∆∞a c√≥ d·ªØ li·ªáu
            st.markdown("#### üì• T·∫£i to√†n th·ªã tr∆∞·ªùng")
            st.info("üîç T·ª± ƒë·ªông t√¨m ng√†y g·∫ßn nh·∫•t (l√πi max 10 ng√†y)")
            st.warning("‚è±Ô∏è Qu√° tr√¨nh c√≥ th·ªÉ m·∫•t 30-90 gi√¢y")
            
            with st.expander("‚ÑπÔ∏è Th√¥ng tin"):
                st.markdown("""
                **CafeF Auto s·∫Ω:**
                - üîé Qu√©t 10 ng√†y g·∫ßn nh·∫•t
                - üì• T·∫£i file ZIP (~50-100MB)
                - üì¶ Gi·∫£i n√©n v√† x·ª≠ l√Ω CSV
                - üßπ L√†m s·∫°ch d·ªØ li·ªáu
                - ‚úÖ Tr·∫£ v·ªÅ to√†n b·ªô th·ªã tr∆∞·ªùng
                """)
            
            if st.button("üì• T·∫¢I TO√ÄN TH·ªä TR∆Ø·ªú·ªúNG", use_container_width=True, type="primary"):
                with st.spinner("‚è≥ ƒêang x·ª≠ l√Ω..."):
                    df = get_cafef_all_exchanges()
                    if df is not None and not df.empty:
                        st.info(f"‚úì Nh·∫≠n ƒë∆∞·ª£c {len(df)} b·∫£n ghi")
                        st.info(f"‚úì Columns: {', '.join(df.columns.tolist())}")
                        
                        # L√†m s·∫°ch ticker
                        ticker_series = df['<Ticker>'].dropna().astype(str)
                        ticker_list = [t.strip() for t in ticker_series.unique() 
                                     if t.strip() and t.strip().upper() != 'NAN']
                        
                        if ticker_list:
                            st.session_state['data'] = df
                            st.session_state['stock_list'] = sorted(ticker_list)
                            st.session_state['data_source'] = 'cafef'
                            st.success(f"üéâ L∆∞u th√†nh c√¥ng {len(ticker_list)} m√£!")
                            time.sleep(1)
                            st.rerun()
                        else:
                            st.error("‚ùå Kh√¥ng c√≥ ticker h·ª£p l·ªá")
                    else:
                        st.error("‚ùå Kh√¥ng t·∫£i ƒë∆∞·ª£c d·ªØ li·ªáu")
    
    st.markdown("---")

# === PH·∫¶N 3: ƒêI·ªÄU KHI·ªÇN BI·ªÇU ƒê·ªí (CH·ªà HI·ªÜN KHI C√ì D·ªÆ LI·ªÜU) ===
if 'data' in st.session_state and st.session_state['data'] is not None:
    with st.sidebar:
        st.markdown("### üìä ƒêI·ªÄU KHI·ªÇN BI·ªÇU ƒê·ªí")
        
        df = st.session_state['data']
        
        # L√†m s·∫°ch ticker list
        ticker_series = df['<Ticker>'].dropna().astype(str)
        ticker_list = sorted([t.strip() for t in ticker_series.unique() 
                            if t.strip() and t.strip().upper() != 'NAN'])
        
        if not ticker_list:
            st.error("‚ùå Kh√¥ng c√≥ m√£ h·ª£p l·ªá")
            st.stop()
        
        # Ch·ªçn m√£
        st.markdown("#### üéØ Ch·ªçn m√£ c·ªï phi·∫øu")
        stock_code = st.selectbox(
            f"T·ªïng: {len(ticker_list)} m√£",
            ticker_list,
            label_visibility="collapsed",
            key="stock_selector"
        )
        
        st.markdown("---")
        
        # Lo·∫°i bi·ªÉu ƒë·ªì
        st.markdown("#### üìà Lo·∫°i bi·ªÉu ƒë·ªì")
        chart_type = st.radio(
            "Ch·ªçn:",
            ["üìä N·∫øn Nh·∫≠t", "üìà Line Chart"],
            label_visibility="collapsed"
        )
        chart_type = "N·∫øn Nh·∫≠t" if "N·∫øn" in chart_type else "Line Chart"
        
        st.markdown("---")
        
        # Ch·ªâ b√°o k·ªπ thu·∫≠t
        st.markdown("#### üìä Ch·ªâ b√°o k·ªπ thu·∫≠t")
        
        col1, col2 = st.columns(2)
        with col1:
            show_ma = st.checkbox("MA", value=True)
            show_bb = st.checkbox("Bollinger")
        with col2:
            show_ema = st.checkbox("EMA", value=False)
            show_rsi = st.checkbox("RSI", value=False)
        
        # C·∫•u h√¨nh MA
        if show_ma:
            ma_period = st.slider("Chu k·ª≥ MA:", 5, 50, 20, key="ma")
        
        # C·∫•u h√¨nh EMA
        if show_ema:
            ema_period = st.slider("Chu k·ª≥ EMA:", 5, 50, 12, key="ema")
        
        st.markdown("---")
        
        # Outliers
        st.markdown("#### üî¨ Ph√°t hi·ªán Outliers")
        show_outliers = st.checkbox("Hi·ªán Outliers", value=False)
        
        if show_outliers:
            outlier_method = st.radio(
                "Ph∆∞∆°ng ph√°p:",
                ["IQR", "Z-Score"],
                horizontal=True,
                label_visibility="collapsed"
            )
            
            if outlier_method == "IQR":
                iqr_multiplier = st.slider("IQR Multiplier:", 1.0, 3.0, 1.5, 0.1)
            else:
                zscore_threshold = st.slider("Z-Score:", 2.0, 4.0, 3.0, 0.1)
            
            remove_outlier = st.checkbox("Lo·∫°i b·ªè Outliers")
        
        st.markdown("---")
        
        # C√†i ƒë·∫∑t chart
        st.markdown("#### ‚öôÔ∏è C√†i ƒë·∫∑t")
        chart_height = st.slider("Chi·ªÅu cao:", 500, 1000, 700, 50)
    
    stock_data = df[df['<Ticker>'] == stock_code].sort_values(by='<DTYYYYMMDD>').copy()
    
    if not stock_data.empty:
        original_data = stock_data.copy()
        outliers_data = None
        
        if show_outliers:
            if outlier_method == "IQR":
                outliers_data, lower, upper = detect_outliers_iqr(stock_data, '<Close>', multiplier=iqr_multiplier)
                if remove_outlier:
                    stock_data, _ = remove_outliers(stock_data, '<Close>', method='iqr', multiplier=iqr_multiplier)
            else:
                outliers_data = detect_outliers_zscore(stock_data, '<Close>', threshold=zscore_threshold)
                if remove_outlier:
                    stock_data, _ = remove_outliers(stock_data, '<Close>', method='zscore', threshold=zscore_threshold)
        
        # METRICS
        latest = stock_data.iloc[-1]
        prev = stock_data.iloc[-2] if len(stock_data) > 1 else latest
        
        price_change = latest['<Close>'] - prev['<Close>']
        price_change_pct = (price_change / prev['<Close>'] * 100) if prev['<Close>'] != 0 else 0
        
        col1, col2, col3, col4, col5 = st.columns(5)
        
        with col1:
            st.metric("üí∞ GI√Å ƒê√ìNG", f"{latest['<Close>']:,.2f}", f"{price_change:+,.2f} ({price_change_pct:+.2f}%)")
        with col2:
            st.metric("üìà CAO NH·∫§T", f"{latest['<High>']:,.2f}")
        with col3:
            st.metric("üìâ TH·∫§P NH·∫§T", f"{latest['<Low>']:,.2f}")
        with col4:
            st.metric("üìä KH·ªêI L∆Ø·ª¢NG", f"{latest['<Volume>']:,.0f}")
        with col5:
            avg_volume = stock_data['<Volume>'].tail(20).mean()
            volume_change = ((latest['<Volume>'] - avg_volume) / avg_volume * 100) if avg_volume != 0 else 0
            st.metric("üì¶ TB 20", f"{avg_volume:,.2f}", f"{volume_change:+.2f}%")
        
        if show_outliers and outliers_data is not None and len(outliers_data) > 0:
            st.warning(f"‚ö†Ô∏è Ph√°t hi·ªán {len(outliers_data)} outliers ({outlier_method})")
            if remove_outlier:
                st.info(f"‚úÖ ƒê√£ lo·∫°i b·ªè {len(outliers_data)} outliers")
        
        st.markdown("---")
        st.markdown(f"### üìà Ph√¢n t√≠ch: **{stock_code}**")
        
        time_range = st.select_slider("‚è±Ô∏è Th·ªùi gian:", options=['1 th√°ng', '3 th√°ng', '6 th√°ng', '1 nƒÉm', 'T·∫•t c·∫£'], value='3 th√°ng')
        
        if time_range != 'T·∫•t c·∫£':
            days_map = {'1 th√°ng': 30, '3 th√°ng': 90, '6 th√°ng': 180, '1 nƒÉm': 365}
            cutoff_date = datetime.now() - timedelta(days=days_map[time_range])
            stock_data = stock_data[stock_data['<DTYYYYMMDD>'] >= cutoff_date]
            if outliers_data is not None and not outliers_data.empty:
                outliers_data = outliers_data[outliers_data['<DTYYYYMMDD>'] >= cutoff_date]
        
        if show_ma:
            stock_data['MA'] = calculate_ma(stock_data, ma_period)
        if show_ema:
            stock_data['EMA'] = calculate_ema(stock_data, ema_period)
        if show_bb:
            stock_data['BB_MA'], stock_data['BB_Upper'], stock_data['BB_Lower'] = calculate_bollinger_bands(stock_data)
        if show_rsi:
            stock_data['RSI'] = calculate_rsi(stock_data)
        
        # === PH·∫¶N S·ª¨A L·ªñI HI·ªÇN TH·ªä NG√ÄY ===
        st.markdown('<div class="chart-container">', unsafe_allow_html=True)
        
        rows = 3 if show_rsi else 2
        row_heights = [0.6, 0.2, 0.2] if show_rsi else [0.7, 0.3]
        subplot_titles = [f'üíπ {stock_code}', 'üìä Volume', 'üìâ RSI'] if show_rsi else [f'üíπ {stock_code}', 'üìä Volume']
        
        fig = make_subplots(rows=rows, cols=1, shared_xaxes=True, vertical_spacing=0.03, subplot_titles=subplot_titles, row_heights=row_heights)
        
        # Bi·ªÉu ƒë·ªì ch√≠nh
        if chart_type == "N·∫øn Nh·∫≠t":
            fig.add_trace(go.Candlestick(
                x=stock_data['<DTYYYYMMDD>'],
                open=stock_data['<Open>'],
                high=stock_data['<High>'],
                low=stock_data['<Low>'],
                close=stock_data['<Close>'],
                name="Gi√°",
                increasing_line_color='#5994ce',
                decreasing_line_color='#b957ce'
            ), row=1, col=1)
        else:
            fig.add_trace(go.Scatter(
                x=stock_data['<DTYYYYMMDD>'],
                y=stock_data['<Close>'],
                name="Gi√°",
                line=dict(color='#5994ce', width=2.5),
                fill='tozeroy',
                fillcolor='rgba(89, 148, 206, 0.1)'
            ), row=1, col=1)
        
        # Outliers
        if show_outliers and outliers_data is not None and not outliers_data.empty:
            fig.add_trace(go.Scatter(
                x=outliers_data['<DTYYYYMMDD>'],
                y=outliers_data['<Close>'],
                mode='markers',
                name='Outliers',
                marker=dict(color='#ff4444', size=12, symbol='x', line=dict(color='#ffffff', width=2))
            ), row=1, col=1)
        
        # MA
        if show_ma and 'MA' in stock_data.columns:
            fig.add_trace(go.Scatter(
                x=stock_data['<DTYYYYMMDD>'],
                y=stock_data['MA'],
                name=f'MA{ma_period}',
                line=dict(color='#ffa502', width=2.5)
            ), row=1, col=1)
        
        # EMA
        if show_ema and 'EMA' in stock_data.columns:
            fig.add_trace(go.Scatter(
                x=stock_data['<DTYYYYMMDD>'],
                y=stock_data['EMA'],
                name=f'EMA{ema_period}',
                line=dict(color='#5c58bb', width=2.5)
            ), row=1, col=1)
        
        # Bollinger Bands
        if show_bb and 'BB_Upper' in stock_data.columns:
            fig.add_trace(go.Scatter(x=stock_data['<DTYYYYMMDD>'], y=stock_data['BB_Upper'], name='BB Upper', line=dict(color='rgba(185, 87, 206, 0.5)', width=1, dash='dash'), showlegend=False), row=1, col=1)
            fig.add_trace(go.Scatter(x=stock_data['<DTYYYYMMDD>'], y=stock_data['BB_MA'], name='BB Mid', line=dict(color='rgba(185, 87, 206, 0.8)', width=1.5), showlegend=False), row=1, col=1)
            fig.add_trace(go.Scatter(x=stock_data['<DTYYYYMMDD>'], y=stock_data['BB_Lower'], name='BB Lower', line=dict(color='rgba(185, 87, 206, 0.5)', width=1, dash='dash'), fill='tonexty', fillcolor='rgba(185, 87, 206, 0.1)', showlegend=False), row=1, col=1)
        
        # Volume
        colors = ['#5994ce' if row['<Close>'] >= row['<Open>'] else '#b957ce' for index, row in stock_data.iterrows()]
        fig.add_trace(go.Bar(x=stock_data['<DTYYYYMMDD>'], y=stock_data['<Volume>'], name="Volume", marker_color=colors), row=2, col=1)
        
        # RSI
        if show_rsi and 'RSI' in stock_data.columns:
            fig.add_trace(go.Scatter(x=stock_data['<DTYYYYMMDD>'], y=stock_data['RSI'], name="RSI", line=dict(color='#5c58bb', width=2)), row=3, col=1)
            fig.add_hline(y=70, line_dash="dash", line_color="#b957ce", opacity=0.5, row=3, col=1)
            fig.add_hline(y=30, line_dash="dash", line_color="#5994ce", opacity=0.5, row=3, col=1)
        
        fig.update_layout(
            xaxis_rangeslider_visible=False,
            height=chart_height,
            hovermode='x unified',
            plot_bgcolor='rgba(0,0,0,0)',
            paper_bgcolor='rgba(0,0,0,0)',
            font=dict(color='#ffffff', size=12),
            showlegend=True,
            legend=dict(orientation="h", yanchor="bottom", y=1.01, xanchor="right", x=1, bgcolor='rgba(58, 78, 147, 0.8)'),
            margin=dict(l=10, r=10, t=60, b=10)
        )
        
        for i in range(1, rows + 1):
            fig.update_xaxes(gridcolor='rgba(92, 88, 187, 0.1)', showgrid=True, zeroline=False, row=i, col=1)
            fig.update_yaxes(gridcolor='rgba(92, 88, 187, 0.1)', showgrid=True, zeroline=False, row=i, col=1)
        
        # === PH·∫¶N S·ª¨A L·ªñI L·ªñ TR·ªêNG (T·ª∞ ƒê·ªòNG CHO C·∫¢ NG√ÄY L·ªÑ) ===
        # L·∫•y ra danh s√°ch t·∫•t c·∫£ c√°c ng√†y c√≥ trong d·ªØ li·ªáu ƒëang hi·ªÉn th·ªã
        all_present_dates = pd.to_datetime(stock_data['<DTYYYYMMDD>'])
        
        # Ch·ªâ th·ª±c hi·ªán n·∫øu c√≥ d·ªØ li·ªáu
        if not all_present_dates.empty:
            # T·∫°o ra m·ªôt chu·ªói ng√†y li√™n t·ª•c t·ª´ ng√†y ƒë·∫ßu ƒë·∫øn ng√†y cu·ªëi
            full_date_range = pd.date_range(start=all_present_dates.min(), end=all_present_dates.max())
            
            # T√¨m nh·ªØng ng√†y kh√¥ng c√≥ trong d·ªØ li·ªáu (ch√≠nh l√† ng√†y ngh·ªâ T7, CN, L·ªÖ)
            missing_dates = full_date_range.difference(all_present_dates)
            
            # C·∫≠p nh·∫≠t tr·ª•c X ƒë·ªÉ "b·ªè qua" (·∫©n ƒëi) nh·ªØng ng√†y kh√¥ng c√≥ d·ªØ li·ªáu n√†y
            fig.update_xaxes(rangebreaks=[dict(values=missing_dates)])
        
        fig.update_yaxes(title_text="Gi√° (VNƒê)", row=1, col=1)
        fig.update_yaxes(title_text="Volume", row=2, col=1)
        if show_rsi:
            fig.update_yaxes(title_text="RSI", row=3, col=1, range=[0, 100])
        
        st.plotly_chart(fig, use_container_width=True)
        st.markdown('</div>', unsafe_allow_html=True)
        # === K·∫æT TH√öC PH·∫¶N S·ª¨A L·ªñI ===

        st.markdown("---")
        
        # B·∫¢NG D·ªÆ LI·ªÜU
        st.markdown('<div class="data-table-container">', unsafe_allow_html=True)
        st.markdown("### üìà D·ªÆ LI·ªÜU CHI TI·∫æT & TH·ªêNG K√ä")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.markdown(f"""
                <div class="stats-card">
                    <h4>üìä Th·ªëng k√™ gi√°</h4>
                    <p>TB: {stock_data['<Close>'].mean():,.2f}</p>
                    <p>Std: {stock_data['<Close>'].std():,.2f}</p>
                </div>
            """, unsafe_allow_html=True)
        
        with col2:
            st.markdown(f"""
                <div class="stats-card">
                    <h4>üìà Bi√™n ƒë·ªô</h4>
                    <p>Max: {stock_data['<Close>'].max():,.2f}</p>
                    <p>Min: {stock_data['<Close>'].min():,.2f}</p>
                </div>
            """, unsafe_allow_html=True)
        
        with col3:
            st.markdown(f"""
                <div class="stats-card">
                    <h4>üíπ Volume TB</h4>
                    <p>20 ng√†y: {stock_data['<Volume>'].tail(20).mean():,.2f}</p>
                    <p>T·ªïng: {stock_data['<Volume>'].mean():,.2f}</p>
                </div>
            """, unsafe_allow_html=True)
        
        display_df = stock_data[['<DTYYYYMMDD>', '<Open>', '<High>', '<Low>', '<Close>', '<Volume>']].copy()
        display_df.columns = ['üìÖ Ng√†y', 'üîµ M·ªü', 'üî∫ Cao', 'üîª Th·∫•p', '‚≠ï ƒê√≥ng', 'üìä Volume']
        
        for col in ['üîµ M·ªü', 'üî∫ Cao', 'üîª Th·∫•p', '‚≠ï ƒê√≥ng']:
            display_df[col] = display_df[col].apply(lambda x: f"{x:,.2f}")
        display_df['üìä Volume'] = display_df['üìä Volume'].apply(lambda x: f"{x:,.2f}")
        
        st.dataframe(display_df.sort_values(by='üìÖ Ng√†y', ascending=False).reset_index(drop=True), use_container_width=True, height=450)
        st.markdown("</div>", unsafe_allow_html=True)
    else:
        st.warning(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu cho {stock_code}")
else:
    st.markdown("""
        <div class="data-table-container">
            <h3>üöÄ H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng</h3>
            <ul>
                <li><strong>B∆∞·ªõc 1:</strong> Ch·ªçn ngu·ªìn d·ªØ li·ªáu (vnstock3 API ho·∫∑c CafeF Auto)</li>
                <li><strong>B∆∞·ªõc 2:</strong> Ch·ªçn ch·∫ø ƒë·ªô t·∫£i (1 m√£ ho·∫∑c to√†n th·ªã tr∆∞·ªùng)</li>
                <li><strong>B∆∞·ªõc 3:</strong> Nh·∫•n n√∫t t·∫£i d·ªØ li·ªáu</li>
                <li><strong>B∆∞·ªõc 4:</strong> Ph√¢n t√≠ch v·ªõi c√°c ch·ªâ b√°o k·ªπ thu·∫≠t</li>
            </ul>
            <br>
            <h3>‚ú® T√≠nh nƒÉng n·ªïi b·∫≠t</h3>
            <ul>
                <li>üì° <strong>vnstock3 API:</strong> D·ªØ li·ªáu real-time t·ª´ TCBS</li>
                <li>üì¶ <strong>CafeF Auto:</strong> T·ª± ƒë·ªông t√¨m ng√†y c√≥ d·ªØ li·ªáu g·∫ßn nh·∫•t (l√πi t·ªëi ƒëa 10 ng√†y)</li>
                <li>üîÑ <strong>Auto fallback:</strong> Chuy·ªÉn ngu·ªìn t·ª± ƒë·ªông khi API l·ªói</li>
                <li>üìä <strong>Bi·ªÉu ƒë·ªì:</strong> N·∫øn Nh·∫≠t & Line Chart v·ªõi hi·ªáu ·ª©ng ƒë·∫πp m·∫Øt</li>
                <li>üìà <strong>Ch·ªâ b√°o:</strong> MA, EMA, Bollinger Bands, RSI</li>
                <li>üî¨ <strong>Outliers:</strong> Ph√°t hi·ªán b·∫±ng IQR ho·∫∑c Z-Score</li>
                <li>üé® <strong>UI/UX:</strong> Glassmorphism v·ªõi gradient ƒë·ªông</li>
            </ul>
            <br>
            <h3>üí° L·ª±a ch·ªçn ngu·ªìn d·ªØ li·ªáu</h3>
            <table style="width:100%; color: white;">
                <tr style="background: rgba(92, 88, 187, 0.3);">
                    <th style="padding: 0.5rem;">T√¨nh hu·ªëng</th>
                    <th style="padding: 0.5rem;">Ngu·ªìn ƒë·ªÅ xu·∫•t</th>
                    <th style="padding: 0.5rem;">∆Øu ƒëi·ªÉm</th>
                </tr>
                <tr>
                    <td style="padding: 0.5rem;">Ph√¢n t√≠ch 1 m√£ c·ª• th·ªÉ</td>
                    <td style="padding: 0.5rem;">üì° vnstock3</td>
                    <td style="padding: 0.5rem;">Nhanh, real-time</td>
                </tr>
                <tr>
                    <td style="padding: 0.5rem;">So s√°nh nhi·ªÅu m√£</td>
                    <td style="padding: 0.5rem;">üì¶ CafeF</td>
                    <td style="padding: 0.5rem;">To√†n th·ªã tr∆∞·ªùng</td>
                </tr>
                <tr>
                    <td style="padding: 0.5rem;">Ph√¢n t√≠ch l·ªãch s·ª≠</td>
                    <td style="padding: 0.5rem;">üì¶ CafeF</td>
                    <td style="padding: 0.5rem;">D·ªØ li·ªáu ƒëi·ªÅu ch·ªânh</td>
                </tr>
                <tr>
                    <td style="padding: 0.5rem;">API b·ªã l·ªói</td>
                    <td style="padding: 0.5rem;">üì¶ CafeF</td>
                    <td style="padding: 0.5rem;">Lu√¥n s·∫µn s√†ng</td>
                </tr>
            </table>
            <br>
            <h3>üéØ CafeF Auto - C√°ch ho·∫°t ƒë·ªông</h3>
            <p>H·ªá th·ªëng s·∫Ω t·ª± ƒë·ªông:</p>
            <ol>
                <li>üîç Qu√©t ng∆∞·ª£c 10 ng√†y g·∫ßn nh·∫•t</li>
                <li>‚úÖ T√¨m ng√†y c√≥ d·ªØ li·ªáu kh·∫£ d·ª•ng</li>
                <li>üì• T·∫£i file ZIP t·ª´ CafeF CDN</li>
                <li>üì¶ Gi·∫£i n√©n v√† x·ª≠ l√Ω CSV</li>
                <li>üßπ L√†m s·∫°ch v√† chu·∫©n h√≥a d·ªØ li·ªáu</li>
                <li>‚ú® Tr·∫£ v·ªÅ DataFrame s·∫µn s√†ng ph√¢n t√≠ch</li>
            </ol>
        </div>
    """, unsafe_allow_html=True)

